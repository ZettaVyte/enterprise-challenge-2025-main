# dashboard_clickbus.py

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.cluster import KMeans
import xgboost as xgb

# --- Configura√ß√£o da P√°gina ---
st.set_page_config(
    page_title="Dashboard Preditivo - ClickBus",
    page_icon="üöå",
    layout="wide"
)

# --- Fun√ß√µes de Processamento e Cache ---

@st.cache_data
def load_and_process_data(file_path):
    """Carrega os dados da amostra e faz o pr√©-processamento inicial."""
    df = pd.read_csv(file_path)
    df['datetime_purchase'] = pd.to_datetime(df['date_purchase'] + ' ' + df['time_purchase'])
    df['route'] = df['place_origin_departure'] + ' -> ' + df['place_destination_departure']
    return df

@st.cache_data
def generate_segmented_data(_df): # O underline evita que o Streamlit hasheie o DF inteiro
    """Executa o modelo K-Means para gerar os dados de segmenta√ß√£o em mem√≥ria."""
    df_copy = _df.copy()
    snapshot_date = df_copy['datetime_purchase'].max() + pd.Timedelta(days=1)
    
    rfm_data = df_copy.groupby('fk_contact').agg({
        'datetime_purchase': lambda date: (snapshot_date - date.max()).days,
        'nk_ota_localizer_id': 'count',
        'gmv_success': 'sum'
    }).reset_index()
    
    rfm_data.rename(columns={'datetime_purchase': 'Recency', 'nk_ota_localizer_id': 'Frequency', 'gmv_success': 'MonetaryValue'}, inplace=True)
    
    rfm_for_scaling = rfm_data[['Recency', 'Frequency', 'MonetaryValue']]
    scaler = StandardScaler()
    rfm_scaled = scaler.fit_transform(rfm_for_scaling)
    
    kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)
    rfm_data['Cluster'] = kmeans.fit_predict(rfm_scaled)
    
    return rfm_data

# --- Carregamento dos Dados ---
try:
    df_processed = load_and_process_data('data/df_amostra.csv') 
    df_segmented = generate_segmented_data(df_processed)
except FileNotFoundError:
    st.error("Erro: Arquivo 'data/df_amostra.csv' n√£o encontrado no reposit√≥rio. Por favor, certifique-se de que a amostra de dados foi enviada ao GitHub.")
    st.stop()

st.title("üöå Dashboard de Modelos de Dados - An√°lise de Clientes ClickBus")
st.markdown("Este dashboard apresenta os resultados dos tr√™s principais desafios de modelagem de dados.")

tab1, tab2, tab3 = st.tabs([
    "üéØ **1. Segmenta√ß√£o de Clientes (K-Means)**",
    "üó∫Ô∏è **2. Previs√£o de Pr√≥xima Rota (RandomForest)**",
    "üìà **3. Previs√£o de Recompra (XGBoost)**"
])

# --- ABA 1: SEGMENTA√á√ÉO DE CLIENTES ---
with tab1:
    st.header("Segmenta√ß√£o de Clientes com RFM e K-Means")
    # ... (O resto do c√≥digo da Aba 1 continua igual, pois `df_segmented` agora √© gerado em mem√≥ria)
    cluster_analysis = df_segmented.groupby('Cluster')[['Recency', 'Frequency', 'MonetaryValue']].mean().sort_values(by='MonetaryValue', ascending=False)
    personas = {
        2: {"nome": "üèÜ Super Clientes (Campe√µes)", "desc": "A elite absoluta. Frequ√™ncia e valor monet√°rio ordens de magnitude acima dos demais. Provavelmente ag√™ncias ou empresas. A√ß√£o: Tratamento VIP, gerente de contas dedicado."},
        3: {"nome": "‚ù§Ô∏è Clientes Fi√©is", "desc": "Compram muito recentemente, com alta frequ√™ncia e gastam bastante. S√£o a base de clientes recorrentes e engajados. A√ß√£o: Programas de fidelidade, ofertas exclusivas."},
        0: {"nome": "üí° Clientes Ocasionales", "desc": "Compram com baixa frequ√™ncia e n√£o o fazem h√° mais de um ano. Precisam de um incentivo para n√£o se tornarem inativos. A√ß√£o: Campanhas de reengajamento com descontos."},
        1: {"nome": "üëª Clientes Perdidos (Inativos)", "desc": "A √∫ltima compra foi h√° quase 6 anos. Clientes efetivamente perdidos, com baix√≠ssimo valor. A√ß√£o: Focar esfor√ßos de marketing nos outros grupos."}
    }
    cluster_analysis['Persona'] = cluster_analysis.index.map(lambda x: personas.get(x, {"nome": "N√£o Definido"})['nome'])
    cluster_analysis['A√ß√£o Sugerida'] = cluster_analysis.index.map(lambda x: personas.get(x, {"desc": "A√ß√£o: N/A"})['desc'].split("A√ß√£o: ")[1])
    st.subheader("Resumo dos Segmentos (Personas)")
    st.dataframe(cluster_analysis[['Persona', 'Recency', 'Frequency', 'MonetaryValue', 'A√ß√£o Sugerida']].style.format({
        'Recency': '{:.0f} dias',
        'Frequency': '{:.1f} compras',
        'MonetaryValue': 'R$ {:,.2f}'
    }))
    st.subheader("Visualiza√ß√£o Interativa dos Clusters")
    col1, col2 = st.columns(2)
    with col1:
        df_segmented['MonetaryValueSize'] = df_segmented['MonetaryValue'].clip(lower=0)
        fig_scatter = px.scatter(
            df_segmented, x='Recency', y='Frequency', color='Cluster', size='MonetaryValueSize',
            hover_name='fk_contact', hover_data={'MonetaryValue': True, 'MonetaryValueSize': False},
            title='Vis√£o Geral dos Clusters (RFM)', labels={'Recency': 'Rec√™ncia (dias)', 'Frequency': 'Frequ√™ncia (compras)'},
            color_continuous_scale=px.colors.sequential.Viridis
        )
        st.plotly_chart(fig_scatter, use_container_width=True)
    with col2:
        fig_bar = px.bar(
            cluster_analysis.sort_values('MonetaryValue'), x='MonovoletaryValue', y='Persona', orientation='h',
            color='Persona', title='Valor Monet√°rio M√©dio por Segmento', labels={'MonetaryValue': 'Valor M√©dio (R$)', 'Persona': 'Segmento'}
        )
        st.plotly_chart(fig_bar, use_container_width=True)
        
# --- ABA 2: PREVIS√ÉO DE RECOMPRA ---
with tab2:
    st.header("Previs√£o de Recompra nos Pr√≥ximos 30 Dias")
    st.markdown("""
    Aqui, o desafio √© identificar quais clientes t√™m a maior probabilidade de realizar uma nova compra no pr√≥ximo m√™s.
    Constru√≠mos um modelo **XGBoost** que, apesar de uma precis√£o aparentemente baixa, oferece um grande valor de neg√≥cio.
    """)

    # --- L√≥gica do Modelo (em cache para performance) ---
    @st.cache_resource
    def train_repurchase_model(df):
        # 1. Janela de predi√ß√£o
        cutoff_date = df['datetime_purchase'].max() - pd.Timedelta(days=30)
        df_train = df[df['datetime_purchase'] < cutoff_date]
        df_target = df[df['datetime_purchase'] >= cutoff_date]
        snapshot_date_model = cutoff_date + pd.Timedelta(days=1)
        
        # 2. Features
        features_df = df_train.groupby('fk_contact').agg(
            Recency=('datetime_purchase', lambda date: (snapshot_date_model - date.max()).days),
            Frequency=('datetime_purchase', 'count'),
            MonetaryValue=('gmv_success', 'sum')
        ).reset_index()

        # 3. Alvo
        target_customers = df_target['fk_contact'].unique()
        features_df['will_buy_in_30_days'] = features_df['fk_contact'].isin(target_customers).astype(int)
        
        X = features_df[['Recency', 'Frequency', 'MonetaryValue']]
        y = features_df['will_buy_in_30_days']
        
        # 4. Par√¢metro de balanceamento
        scale_pos_weight = y.value_counts()[0] / y.value_counts()[1]
        
        # 5. Treinar modelo
        model = xgb.XGBClassifier(
            scale_pos_weight=scale_pos_weight, use_label_encoder=False, 
            eval_metric='logloss', random_state=42
        )
        model.fit(X, y)
        return model, X, y

    xgb_repurchase_model, X_repurchase, y_repurchase = train_repurchase_model(df_processed)
    
    # --- Exibi√ß√£o dos Resultados ---
    st.subheader("O Valor de Neg√≥cio do Modelo XGBoost")
    st.markdown("""
    Embora a **precis√£o** do modelo seja de **12%** (com limiar ajustado), isso representa um ganho enorme. Se a taxa de recompra natural √© de ~2.6%, nosso modelo √© **4.6x mais eficaz** em encontrar clientes propensos a comprar.
    """)
    
    col1, col2 = st.columns(2)
    with col1:
        st.info("**Perfil do Modelo (XGBoost com limiar ajustado para 0.6)**")
        st.markdown("- **Precis√£o (Precision): 12%**\n    - *De cada 100 clientes que o modelo aponta, 12 realmente compram.*")
        st.markdown("- **Alcance (Recall): 70%**\n    - *O modelo consegue encontrar 70% de todos os clientes que de fato recompraram.*")
        
    with col2:
        fig_lift = go.Figure(go.Indicator(
            mode = "gauge+number",
            value = 4.6,
            title = {'text': "Ganho de Efici√™ncia (Lift) vs. Abordagem Gen√©rica"},
            gauge = {'axis': {'range': [1, 10]}, 'bar': {'color': "green"}},
            domain = {'x': [0, 1], 'y': [0, 1]}
        ))
        st.plotly_chart(fig_lift, use_container_width=True)
    
    st.subheader("Estrat√©gia de Uso")
    st.success("""
    **Este modelo √© ideal para campanhas de marketing de baixo custo e grande escala (ex: e-mail marketing).** Ele nos permite focar em um grupo muito mais qualificado de clientes, maximizando o alcance e o retorno sobre o investimento.
    """)

st.sidebar.header("Sobre o Projeto")
st.sidebar.info("""
Este dashboard √© o resultado de uma an√°lise de dados completa para a ClickBus, cobrindo desde a segmenta√ß√£o de clientes at√© a cria√ß√£o de modelos preditivos avan√ßados.
- **Tecnologias:** Python, Pandas, Scikit-learn, XGBoost, Streamlit, Plotly.
- **Objetivo:** Transformar dados brutos em insights acion√°veis e ferramentas estrat√©gicas para o neg√≥cio.
""")
